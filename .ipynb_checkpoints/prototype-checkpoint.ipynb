{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cf47b8b5-6998-47e6-9cf1-a3cdb6429f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import pdb\n",
    "from scipy.stats import chi2_contingency\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "676a860b-24b0-4842-b34f-95ffad02879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tests/data-tiniest2/data.txt\", delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "572520ae-43c8-4cbb-a2e3-b0f1b274d7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'num1', 'num2', 'num3'], dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "49bff3c6-674d-44d3-af83-8b78bcc408ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    quartile_edges= np.percentile(df[col].values, [25,50,75,100],method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3cbfd45-9777-4b02-84a9-1dfbcf73d853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   target  60 non-null     float64\n",
      " 1   num1    60 non-null     float64\n",
      " 2   num2    60 non-null     int64  \n",
      " 3   num3    60 non-null     float64\n",
      "dtypes: float64(3), int64(1)\n",
      "memory usage: 2.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "907705ad-4e2a-47a4-afbb-ede9e3df299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up test case for particular node\n",
    "NODE_2 = False\n",
    "if NODE_2:\n",
    "    old_df = df\n",
    "    df = df.loc[df['num2'] <= 5.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ac2efe8-40db-433f-b750-4f2e7ae36988",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable selection\n",
    "def _calc_chi2_stat(y_mean, col) -> np.float64:\n",
    "    \"\"\" Split numeric into 4 quartiles, split categoricals into c bins\n",
    "    Calculate chi2_contingency and return p-value \"\"\"\n",
    "    # @NOTE: can we use pvalues as is or do I need to use modified wilson-hilferty to \n",
    "    # get the chi-squared degree 1 and rank the variables like that? The 2002 regression\n",
    "    # paper says to sort based on p-values but the tutorial video part 1 says to rank\n",
    "    # based on the chi-squared degree of freedom 1. Note the video is 20 years older\n",
    "    # than the paper.\n",
    "    residuals = df.target - y_mean\n",
    "    pvalue = 999.99\n",
    "\n",
    "    # Convert the column to a NumPy array\n",
    "    column_array = df[col].values\n",
    "    indexes = df[col].index.values\n",
    "    # Bin the quartiles\n",
    "    quartile_edges = np.percentile(\n",
    "        column_array, [25, 50, 75, 100], method='linear')\n",
    "    # Bin the data using np.digitize\n",
    "    quartile_bins = np.digitize(\n",
    "        column_array, quartile_edges, right=True)\n",
    "    # Create a defaultdict to store grouped indexes\n",
    "    grouped_indexes = defaultdict(list)\n",
    "\n",
    "    # Iterate through the bins and indexes arrays\n",
    "    for bin_value, index in zip(quartile_bins, indexes):\n",
    "        grouped_indexes[bin_value].append(index)\n",
    "\n",
    "    grouped_index_keys = list(grouped_indexes.keys())\n",
    "    num_groups = len(grouped_indexes.keys())\n",
    "    chi_squared = np.zeros(shape=(2, num_groups))\n",
    "    for _bin in range(0, num_groups):\n",
    "        chi_squared[0, _bin] = (\n",
    "            residuals[grouped_indexes[grouped_index_keys[_bin]]] >= 0).sum()\n",
    "        chi_squared[1, _bin] = (\n",
    "            residuals[grouped_indexes[grouped_index_keys[_bin]]] < 0).sum()\n",
    "    print(chi_squared)\n",
    "    statistic = chi2_contingency(chi_squared).statistic\n",
    "    dof = chi2_contingency(chi_squared).dof\n",
    "    print(f\"statistic, dof = {statistic} {dof}\")\n",
    "    return statistic\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75e78cf5-4378-4ad1-b8a3-0eda89c75eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  5. 10. 15.]\n",
      " [14. 10.  5.  0.]]\n",
      "statistic, dof = 29.566184649610676 3\n",
      "[[ 9.  5. 12.  5.]\n",
      " [ 7.  9.  2. 11.]]\n",
      "statistic, dof = 10.730970920069918 3\n",
      "[[8. 7. 8. 8.]\n",
      " [8. 9. 6. 6.]]\n",
      "statistic, dof = 0.7556014619418404 3\n"
     ]
    }
   ],
   "source": [
    "## _get_best_variable function\n",
    "split_vars = ['num1','num2','num3']\n",
    "node_y_mean = df.target.mean()\n",
    "residuals = df.target - node_y_mean\n",
    "\n",
    "stat_pval = {\n",
    "    col: _calc_chi2_stat(\n",
    "        y_mean=node_y_mean,\n",
    "        col=col) for col in split_vars}\n",
    "# numerical val          |  0   0.25% | 0.25 to 0.50 | 0.50 to 0.75 | 0.75 - 1.0 |\n",
    "#                   pos\n",
    "#                   neg\n",
    "\n",
    "# categorical val\n",
    "#                        |   cat1     |   cat2       |    cat3      |   NA       | ... etc\n",
    "#                   pos\n",
    "#                   neg\n",
    "top_3_keys = {key: value for key, value in stat_pval.items(\n",
    ") if value in heapq.nsmallest(3, stat_pval.values())}\n",
    "top_3_keys = sorted(top_3_keys.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ef7d995-27ee-4999-85c9-a9e7ee727d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('num1', 29.566184649610676),\n",
       " ('num2', 10.730970920069918),\n",
       " ('num3', 0.7556014619418404)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Top-ranked variables and 1-df chi-squared values at root node\n",
    "      1  0.2245E+02   num1\n",
    "      2  0.6132E+01   num2\n",
    "      3  0.3108E-01   num3\n",
    "\"\"\"\n",
    "\n",
    "top_3_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1d1361a9-7e46-43cf-a07f-f2950967d268",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_var = top_3_keys[0][0]\n",
    "col = split_var\n",
    "x_uniq = df[col].drop_duplicates().sort_values()\n",
    "cutpoints = x_uniq[:-1] + np.diff(x_uniq)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "322b4982-86a1-463e-ba2e-8b1e08aa04ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngreatest_tot_sse = None\\nnode_sse = ((df.target - df.target.mean())**2).sum()\\nbest_cut = None\\n\\nfor cut in cutpoints:\\n    right_idx = df[df[col] > cut].index\\n    left_idx = df.drop(right_idx, axis=0).index\\n    left_mean = df.loc[left_idx].target.mean()\\n    right_mean = df.loc[right_idx].target.mean()\\n    tot_items = len(left_idx) + len(right_idx)\\n    #left_sse = ((df.loc[left_idx].target - left_mean)**2).sum()\\n    #right_sse = ((df.loc[right_idx].target - right_mean)**2).sum()\\n    nAL = len(left_idx)\\n    nAR = len(right_idx)\\n    cut_sse = (nAL * nAR / tot_items) * (left_mean - right_mean)**2\\n    #weights = 1, len(left_idx) / tot_items, len(right_idx) / tot_items\\n    #cut_sse = weights[0]*node_sse - weights[1]*left_sse - weights[2]*right_sse\\n    print(cut, cut_sse)\\n    if greatest_tot_sse == None or cut_sse > greatest_tot_sse:\\n        greatest_tot_sse = cut_sse\\n        best_cut = cut\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "greatest_tot_sse = None\n",
    "node_sse = ((df.target - df.target.mean())**2).sum()\n",
    "best_cut = None\n",
    "\n",
    "for cut in cutpoints:\n",
    "    right_idx = df[df[col] > cut].index\n",
    "    left_idx = df.drop(right_idx, axis=0).index\n",
    "    left_mean = df.loc[left_idx].target.mean()\n",
    "    right_mean = df.loc[right_idx].target.mean()\n",
    "    tot_items = len(left_idx) + len(right_idx)\n",
    "    #left_sse = ((df.loc[left_idx].target - left_mean)**2).sum()\n",
    "    #right_sse = ((df.loc[right_idx].target - right_mean)**2).sum()\n",
    "    nAL = len(left_idx)\n",
    "    nAR = len(right_idx)\n",
    "    cut_sse = (nAL * nAR / tot_items) * (left_mean - right_mean)**2\n",
    "    #weights = 1, len(left_idx) / tot_items, len(right_idx) / tot_items\n",
    "    #cut_sse = weights[0]*node_sse - weights[1]*left_sse - weights[2]*right_sse\n",
    "    print(cut, cut_sse)\n",
    "    if greatest_tot_sse == None or cut_sse > greatest_tot_sse:\n",
    "        greatest_tot_sse = cut_sse\n",
    "        best_cut = cut\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68f426-c774-4e8e-bb9c-0cc333295248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ea18f-1820-465e-abf5-8716779f92e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101609ad-17c0-4fce-9363-ba2dc1ed713a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
